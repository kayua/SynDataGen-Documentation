<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 15.0.1"/>
    <title>main API documentation</title>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#ffffcc}.pdoc-code{background:#f8f8f8;}.pdoc-code .c{color:#3D7B7B; font-style:italic}.pdoc-code .err{border:1px solid #FF0000}.pdoc-code .k{color:#008000; font-weight:bold}.pdoc-code .o{color:#666666}.pdoc-code .ch{color:#3D7B7B; font-style:italic}.pdoc-code .cm{color:#3D7B7B; font-style:italic}.pdoc-code .cp{color:#9C6500}.pdoc-code .cpf{color:#3D7B7B; font-style:italic}.pdoc-code .c1{color:#3D7B7B; font-style:italic}.pdoc-code .cs{color:#3D7B7B; font-style:italic}.pdoc-code .gd{color:#A00000}.pdoc-code .ge{font-style:italic}.pdoc-code .gr{color:#E40000}.pdoc-code .gh{color:#000080; font-weight:bold}.pdoc-code .gi{color:#008400}.pdoc-code .go{color:#717171}.pdoc-code .gp{color:#000080; font-weight:bold}.pdoc-code .gs{font-weight:bold}.pdoc-code .gu{color:#800080; font-weight:bold}.pdoc-code .gt{color:#0044DD}.pdoc-code .kc{color:#008000; font-weight:bold}.pdoc-code .kd{color:#008000; font-weight:bold}.pdoc-code .kn{color:#008000; font-weight:bold}.pdoc-code .kp{color:#008000}.pdoc-code .kr{color:#008000; font-weight:bold}.pdoc-code .kt{color:#B00040}.pdoc-code .m{color:#666666}.pdoc-code .s{color:#BA2121}.pdoc-code .na{color:#687822}.pdoc-code .nb{color:#008000}.pdoc-code .nc{color:#0000FF; font-weight:bold}.pdoc-code .no{color:#880000}.pdoc-code .nd{color:#AA22FF}.pdoc-code .ni{color:#717171; font-weight:bold}.pdoc-code .ne{color:#CB3F38; font-weight:bold}.pdoc-code .nf{color:#0000FF}.pdoc-code .nl{color:#767600}.pdoc-code .nn{color:#0000FF; font-weight:bold}.pdoc-code .nt{color:#008000; font-weight:bold}.pdoc-code .nv{color:#19177C}.pdoc-code .ow{color:#AA22FF; font-weight:bold}.pdoc-code .w{color:#bbbbbb}.pdoc-code .mb{color:#666666}.pdoc-code .mf{color:#666666}.pdoc-code .mh{color:#666666}.pdoc-code .mi{color:#666666}.pdoc-code .mo{color:#666666}.pdoc-code .sa{color:#BA2121}.pdoc-code .sb{color:#BA2121}.pdoc-code .sc{color:#BA2121}.pdoc-code .dl{color:#BA2121}.pdoc-code .sd{color:#BA2121; font-style:italic}.pdoc-code .s2{color:#BA2121}.pdoc-code .se{color:#AA5D1F; font-weight:bold}.pdoc-code .sh{color:#BA2121}.pdoc-code .si{color:#A45A77; font-weight:bold}.pdoc-code .sx{color:#008000}.pdoc-code .sr{color:#A45A77}.pdoc-code .s1{color:#BA2121}.pdoc-code .ss{color:#19177C}.pdoc-code .bp{color:#008000}.pdoc-code .fm{color:#0000FF}.pdoc-code .vc{color:#19177C}.pdoc-code .vg{color:#19177C}.pdoc-code .vi{color:#19177C}.pdoc-code .vm{color:#19177C}.pdoc-code .il{color:#666666}</style>
    <style>/*! theme.css */:root{--pdoc-background:#fff;}.pdoc{--text:#212529;--muted:#6c757d;--link:#3660a5;--link-hover:#1659c5;--code:#f8f8f8;--active:#fff598;--accent:#eee;--accent2:#c1c1c1;--nav-hover:rgba(255, 255, 255, 0.5);--name:#0066BB;--def:#008800;--annotation:#007020;}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;z-index:999;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;opacity:0;}nav.pdoc{--pad:clamp(0.5rem, 2vw, 1.75rem);--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent; z-index:1}nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc > div > ul{margin-left:calc(0px - var(--pad));}nav.pdoc li a{padding:.2rem 0 .2rem calc(var(--pad) + var(--indent));}nav.pdoc > div > ul > li > a{padding-left:var(--pad);}nav.pdoc li{transition:all 100ms;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{cursor:pointer;display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .alert{padding:1rem 1rem 1rem calc(1.5rem + 24px);border:1px solid transparent;border-radius:.25rem;background-repeat:no-repeat;background-position:.75rem center;margin-bottom:1rem;}.pdoc .alert > em{display:none;}.pdoc .alert > *:last-child{margin-bottom:0;}.pdoc .alert.note {color:#084298;background-color:#cfe2ff;border-color:#b6d4fe;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23084298%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8%2016A8%208%200%201%200%208%200a8%208%200%200%200%200%2016zm.93-9.412-1%204.705c-.07.34.029.533.304.533.194%200%20.487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703%200-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381%202.29-.287zM8%205.5a1%201%200%201%201%200-2%201%201%200%200%201%200%202z%22/%3E%3C/svg%3E");}.pdoc .alert.warning{color:#664d03;background-color:#fff3cd;border-color:#ffecb5;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23664d03%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8.982%201.566a1.13%201.13%200%200%200-1.96%200L.165%2013.233c-.457.778.091%201.767.98%201.767h13.713c.889%200%201.438-.99.98-1.767L8.982%201.566zM8%205c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%205.995A.905.905%200%200%201%208%205zm.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2z%22/%3E%3C/svg%3E");}.pdoc .alert.danger{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5.52.359A.5.5%200%200%201%206%200h4a.5.5%200%200%201%20.474.658L8.694%206H12.5a.5.5%200%200%201%20.395.807l-7%209a.5.5%200%200%201-.873-.454L6.823%209.5H3.5a.5.5%200%200%201-.48-.641l2.5-8.5z%22/%3E%3C/svg%3E");}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc > section:not(.module-info) h1{font-size:1.5rem;font-weight:500;}.pdoc > section:not(.module-info) h2{font-size:1.4rem;font-weight:500;}.pdoc > section:not(.module-info) h3{font-size:1.3rem;font-weight:500;}.pdoc > section:not(.module-info) h4{font-size:1.2rem;}.pdoc > section:not(.module-info) h5{font-size:1.1rem;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--accent);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc > section:not(.module-info){margin-bottom:1.5rem;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.view-source-toggle-state,.view-source-toggle-state ~ .pdoc-code{display:none;}.view-source-toggle-state:checked ~ .pdoc-code{display:block;}.view-source-button{display:inline-block;float:right;font-size:.75rem;line-height:1.5rem;color:var(--muted);padding:0 .4rem 0 1.3rem;cursor:pointer;text-indent:-2px;}.view-source-button > span{visibility:hidden;}.module-info .view-source-button{float:none;display:flex;justify-content:flex-end;margin:-1.2rem .4rem -.2rem 0;}.view-source-button::before{position:absolute;content:"View Source";display:list-item;list-style-type:disclosure-closed;}.view-source-toggle-state:checked ~ .attr .view-source-button::before,.view-source-toggle-state:checked ~ .view-source-button::before{list-style-type:disclosure-open;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc section:not(.module-info) .docstring{margin-left:clamp(0rem, 5vw - 2rem, 1rem);}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target,.pdoc .pdoc-code > pre > span:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc .pdoc-code > pre > span:target{display:block;}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc *{scroll-margin:2rem;}.pdoc .pdoc-code .linenos{user-select:none;}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc section, .pdoc .classattr{position:relative;}.pdoc .headerlink{--width:clamp(1rem, 3vw, 2rem);position:absolute;top:0;left:calc(0rem - var(--width));transition:all 100ms ease-in-out;opacity:0;}.pdoc .headerlink::before{content:"#";display:block;text-align:center;width:var(--width);height:2.3rem;line-height:2.3rem;font-size:1.5rem;}.pdoc .attr:hover ~ .headerlink,.pdoc *:target > .headerlink,.pdoc .headerlink:hover{opacity:1;}.pdoc .attr{display:block;margin:.5rem 0 .5rem;padding:.4rem .4rem .4rem 1rem;background-color:var(--accent);overflow-x:auto;}.pdoc .classattr{margin-left:2rem;}.pdoc .decorator-deprecated{color:#842029;}.pdoc .decorator-deprecated ~ span{filter:grayscale(1) opacity(0.8);}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{background-color:transparent;}.pdoc .param, .pdoc .return-annotation{white-space:pre;}.pdoc .signature.multiline .param{display:block;}.pdoc .signature.condensed .param{display:inline-block;}.pdoc .annotation{color:var(--annotation);}.pdoc .view-value-toggle-state,.pdoc .view-value-toggle-state ~ .default_value{display:none;}.pdoc .view-value-toggle-state:checked ~ .default_value{display:inherit;}.pdoc .view-value-button{font-size:.5rem;vertical-align:middle;border-style:dashed;margin-top:-0.1rem;}.pdoc .view-value-button:hover{background:white;}.pdoc .view-value-button::before{content:"show";text-align:center;width:2.2em;display:inline-block;}.pdoc .view-value-toggle-state:checked ~ .view-value-button::before{content:"hide";}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:35px;vertical-align:middle;width:70px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
        <style>.welcome-message {
    margin: 40px 0;
    padding: 15px;
    background: rgba(10, 50, 80, 0.05);
    border-left: 4px solid #1a6f90;
    width: 150%; /* Increased width by 20% */
    max-width: 150%; /* Ensure it doesn't exceed 120% of parent */
    box-sizing: border-box; /* Include padding in width calculation */
}

.features-section {
    margin: 25px 0;
    padding: 15px;
    background: white;
    border-radius: 5px;
    box-shadow: 0 2px 5px rgba(0,0,0,0.05);
}

.model-table {
    width: 100%;
    border-collapse: collapse;
    margin: 15px 0;
}

.model-table th, .model-table td {
    padding: 10px;
    border: 1px solid #ddd;
    text-align: left;
}

.model-table th {
    background-color: #f5f9fc;
    font-weight: 900;
}

.features-list, .metrics-list {
    columns: 2;
    -webkit-columns: 2;
    -moz-columns: 2;
    list-style-type: none;
    padding-left: 0;
}

.features-list li, .metrics-list li {
    padding: 5px 0;
    break-inside: avoid;
}

pre {
    background: #f5f9fc;
    padding: 15px;
    border-radius: 5px;
    overflow-x: auto;
}

code {
    font-family: 'Courier New', monospace;
    color: #333;
}

@media (max-width: 920px) {
    .features-list, .metrics-list {
        columns: 1;
        -webkit-columns: 1;
        -moz-columns: 1;
    }
}</style>
    <style>/*! custom.css */</style></head>

<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>

            <h3>
                <img src="Documentation/Icon/Logo.png" alt="API Icon" width="54" height="54" style="vertical-align: middle; margin-right: 8px;">
                Synthetic Ocean AI</h3>
            <h4> Documentation</h4>

                <ul class="memberlist">


                    <li>

                        <a class="class" href="Documentation/SynDataGen/index.html">SynDataGen()</a>


                    </li>



                    <li>

                        <a class="class" href="Documentation/AdversarialAlgorithm/index.html">AdversarialAlgorithm()</a>


                    </li>



                    <li>

                        <a class="class" href="Documentation/AutoencoderAlgorithm/index.html">AutoencoderAlgorithm()</a>


                    </li>

                    <li>

                        <a class="class" href="Documentation/DiffusionAlgorithm/index.html">DiffusionAlgorithm()</a>


                    </li>

                    <li>

                        <a class="class" href="Documentation/VariationalAutoencoderAlgorithm/index.html">VariationalAutoencoderAlgorithm()</a>


                    </li>

                    <li>

                        <a class="class" href="Documentation/WassersteinGanAlgorithm/index.html">WassersteinGanAlgorithmAlgorithm()</a>


                    </li>



                </ul>


    </nav>
<nav class="pdoc">
    <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
    <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
    <div>
        <h3>
            <img src="Documentation/Icon/Logo.png" alt="API Icon" width="54" height="54" style="vertical-align: middle; margin-right: 8px;">
            Synthetic Ocean AI</h3>
        <h4> Documentation</h4>
        <ul class="memberlist">
            <li><a class="class" href="Documentation/SynDataGen/index.html">SynDataGen()</a></li>
            <li><a class="class" href="Documentation/AdversarialAlgorithm/index.html">AdversarialAlgorithm()</a></li>
            <li><a class="class" href="Documentation/AutoencoderAlgorithm/index.html">AutoencoderAlgorithm()</a></li>
            <li><a class="class" href="Documentation/DiffusionAlgorithm/index.html">DiffusionAlgorithm()</a></li>
            <li><a class="class" href="Documentation/VariationalAutoencoderAlgorithm/index.html">VariationalAutoencoderAlgorithm()</a></li>
            <li><a class="class" href="Documentation/WassersteinGanAlgorithm/index.html">WassersteinGanAlgorithm()</a></li>
        </ul>
    </div>
</nav>

<main class="pdoc">
    <section class="module-info">
        <h1 class="modulename">Synthetic Ocean AI - Data Generation</h1>

        <div class="welcome-message">
            <h2>Synthetic Ocean AI (SynDataGen)</h2>
            <p>An advanced Python framework for generating and evaluating synthetic tabular datasets using modern generative models, including diffusion and adversarial architectures. Designed for researchers and practitioners, it provides reproducible pipelines, fine-grained control over model configuration, and integrated evaluation metrics for realistic data synthesis.</p>

            <div class="features-section">
                <h3>ðŸ§  Architectures Supported</h3>
                <div class="table-container">
                    <table class="model-table">
                        <thead>
                            <tr>
                                <th>Model</th>
                                <th>Description</th>
                                <th>Use Case</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr><td>CGAN</td><td>Conditional GANs conditioned on labels or attributes</td><td>Class balancing, controlled generation</td></tr>
                            <tr><td>WGAN-GP</td><td>Wasserstein GAN with gradient penalty for stable training</td><td>Imbalanced datasets, complex distributions</td></tr>
                            <tr><td>Autoencoder</td><td>Latent-space learning through compression-reconstruction</td><td>Feature extraction, denoising</td></tr>
                            <tr><td>VAE</td><td>Probabilistic Autoencoder with latent sampling</td><td>Probabilistic generation and imputation</td></tr>
                            <tr><td>Denoising Diffusion</td><td>Progressive noise-based generative model</td><td>Robust generation with high-quality samples</td></tr>
                            <tr><td>VQ-VAE</td><td>Discrete latent-space via quantization</td><td>Categorical and mixed-type data</td></tr>
                            <tr><td>Copy/Paste</td><td>Simple sample replication baseline</td><td>Sanity checks, baseline comparison</td></tr>
                            <tr><td>Kernel Diffusion</td><td>Experimental kernelized diffusion process (WIP)</td><td>Future work</td></tr>
                        </tbody>
                    </table>
                </div>
            </div>

            <div class="architecture-section">
                <h2 id="architecture-overview">Architecture Overview</h2>
                <p>The Synthetic Ocean AI library provides several generative architectures:</p>

                <table class="model-table">
                    <thead>
                        <tr>
                            <th>Architecture</th>
                            <th>Key Characteristics</th>
                            <th>Typical Use Cases</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Denoising Probabilistic Diffusion</td>
                            <td>Iterative denoising process, high-quality outputs</td>
                            <td>High-fidelity data generation</td>
                        </tr>
                        <tr>
                            <td>Conditional GAN (CGAN)</td>
                            <td>Label-guided generation</td>
                            <td>Conditional data augmentation</td>
                        </tr>
                        <tr>
                            <td>Wasserstein GAN-GP</td>
                            <td>Stable training with gradient penalty</td>
                            <td>Robust generation tasks</td>
                        </tr>
                        <tr>
                            <td>Conditional Autoencoder</td>
                            <td>Deterministic reconstruction</td>
                            <td>Data compression, denoising</td>
                        </tr>
                        <tr>
                            <td>Variational Autoencoder</td>
                            <td>Probabilistic latent space</td>
                            <td>Diverse sample generation</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <div class="features-section">
                <h2 id="example-workflows">Example Workflows</h2>

                <div class="workflow-section">
                    <h3>Denoising Probabilistic Diffusion</h3>
                    <div class="code-block">
                        <pre><code>import numpy
import tensorflow
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from SynDataGen.Engine.Models.Diffusion.DiffusionModelUnet import UNetModel
from SynDataGen.Engine.Algorithms.Diffusion.AlgorithmDiffusion import DiffusionModel
from SynDataGen.Engine.Algorithms.Diffusion.GaussianDiffusion import GaussianDiffusion
from SynDataGen.Engine.Models.Diffusion.VariationalAutoencoderModel import VariationalModelDiffusion
from SynDataGen.Engine.Algorithms.Diffusion.AlgorithmVariationalAutoencoderDiffusion import VariationalAlgorithmDiffusion

number_samples_per_class = {
    "classes": {1: 100, 2: 200, 3: 150},
    "number_classes": 3
}
input_shape = (1200, )

# Initialize UNet models
first_instance_unet = UNetModel(
    embedding_dimension=128,
    embedding_channels=1,
    list_neurons_per_level=[1, 2, 4],
    list_attentions=[False,True, True],
    number_residual_blocks=2,
    normalization_groups=1,
    intermediary_activation_function='swish',
    intermediary_activation_alpha=0.05,
    last_layer_activation='linear',
    number_samples_per_class=number_samples_per_class
)

second_instance_unet = UNetModel(
    embedding_dimension=128,
    embedding_channels=1,
    list_neurons_per_level=[1, 2, 4],
    list_attentions=[False, False, True, True],
    number_residual_blocks=2,
    normalization_groups=1,
    intermediary_activation_function='swish',
    intermediary_activation_alpha=0.05,
    last_layer_activation='linear',
    number_samples_per_class=number_samples_per_class
)

# Initialize Gaussian Diffusion
gaussian_diffusion_util = GaussianDiffusion(
    beta_start=1e-4,
    beta_end=0.02,
    time_steps=1000,
    clip_min=-1.0,
    clip_max=1.0
)

# Initialize Variational Autoencoder
variation_model_diffusion = VariationalModelDiffusion(
    latent_dimension=128,
    output_shape=input_shape,
    activation_function='swish',
    initializer_mean=0.0,
    initializer_deviation=0.02,
    dropout_decay_encoder=0.2,
    dropout_decay_decoder=0.4,
    last_layer_activation='sigmoid',
    number_neurons_encoder=[128, 64],
    number_neurons_decoder=[64, 128],
    dataset_type=numpy.float32,
    number_samples_per_class=number_samples_per_class
)

# Initialize Diffusion Algorithm
diffusion_algorithm = DiffusionModel(
    first_unet_model=first_instance_unet.build_model(),
    second_unet_model=second_instance_unet.build_model(),
    encoder_model_image=variation_model_diffusion.get_encoder(),
    decoder_model_image=variation_model_diffusion.get_decoder(),
    gdf_util=gaussian_diffusion_util,
    optimizer_autoencoder=Adam(learning_rate=0.0002),
    optimizer_diffusion=Adam(learning_rate=0.0002),
    time_steps=1000,
    ema=0.9999,
    margin=0.001,
    embedding_dimension=128
)

# Train and generate samples
diffusion_algorithm.compile(loss='mse', optimizer=Adam(learning_rate=0.002))
data_embedding = variation_model_diffusion.create_embedding([x_real_samples, to_categorical(y_real_samples)])
diffusion_algorithm.fit(data_embedding, epochs=1000, batch_size=32)
samples = diffusion_algorithm.get_samples(number_samples_per_class)</code></pre>
                    </div>

                    <h4>Diffusion Model Parameters</h4>
                    <table class="parameter-table">
                        <thead>
                            <tr>
                                <th>Parameter</th>
                                <th>Description</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr><td>--diffusion_unet_last_layer_activation</td><td>Activation for last layer of U-Net</td></tr>
                            <tr><td>--diffusion_latent_dimension</td><td>Dimension of latent space</td></tr>
                            <tr><td>--diffusion_unet_num_embedding_channels</td><td>Number of embedding channels</td></tr>
                            <tr><td>--diffusion_unet_channels_per_level</td><td>Channels per level in U-Net</td></tr>
                            <tr><td>--diffusion_unet_batch_size</td><td>Batch size for U-Net training</td></tr>
                            <tr><td>--diffusion_unet_attention_mode</td><td>Attention mode for U-Net</td></tr>
                            <tr><td>--diffusion_unet_num_residual_blocks</td><td>Number of residual blocks</td></tr>
                            <tr><td>--diffusion_unet_group_normalization</td><td>Group normalization value</td></tr>
                            <tr><td>--diffusion_unet_intermediary_activation</td><td>Intermediary activation</td></tr>
                            <tr><td>--diffusion_unet_intermediary_activation_alpha</td><td>Alpha for activation</td></tr>
                            <tr><td>--diffusion_unet_epochs</td><td>Training epochs</td></tr>
                            <tr><td>--diffusion_gaussian_beta_start</td><td>Starting beta value</td></tr>
                            <tr><td>--diffusion_gaussian_beta_end</td><td>Ending beta value</td></tr>
                            <tr><td>--diffusion_gaussian_time_steps</td><td>Number of time steps</td></tr>
                            <tr><td>--diffusion_gaussian_clip_min</td><td>Minimum clipping value</td></tr>
                            <tr><td>--diffusion_gaussian_clip_max</td><td>Maximum clipping value</td></tr>
                        </tbody>
                    </table>
                </div>

                <div class="workflow-section">
                    <h3>Conditional GAN (CGAN)</h3>
                    <div class="code-block">
                        <pre><code>import numpy
import tensorflow
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from SynDataGen.Engine.Models.Adversarial.AdversarialModel import AdversarialModel
from SynDataGen.Engine.Algorithms.Adversarial.AdversarialAlgorithm import AdversarialAlgorithm

number_samples_per_class = {
    "classes": {1: 100, 2: 200, 3: 150},
    "number_classes": 3
}
input_shape = (1200, )

# Initialize Adversarial Model
adversarial_model = AdversarialModel(
    latent_dimension=128,
    output_shape=input_shape,
    activation_function="LeakyReLU",
    initializer_mean=0.0,
    initializer_deviation=0.5,
    dropout_decay_rate_g=0.2,
    dropout_decay_rate_d=0.4,
    last_layer_activation="Sigmoid",
    dense_layer_sizes_g=[128],
    dense_layer_sizes_d=[128],
    dataset_type=numpy.float32,
    number_samples_per_class=number_samples_per_class
)

# Initialize Adversarial Algorithm
adversarial_algorithm = AdversarialAlgorithm(
    generator_model=adversarial_model.get_generator(),
    discriminator_model=adversarial_model.get_discriminator(),
    latent_dimension=128,
    loss_generator='binary_crossentropy',
    loss_discriminator='binary_crossentropy',
    file_name_discriminator="discriminator_model",
    file_name_generator="generator_model",
    models_saved_path="models_saved/",
    latent_mean_distribution=0.0,
    latent_stander_deviation=1.0,
    smoothing_rate=0.15
)

# Train and generate samples
adversarial_algorithm.compile(
    Adam(learning_rate=0.0002, beta_1=0.5),
    Adam(learning_rate=0.0002, beta_1=0.5),
    'binary_crossentropy',
    'binary_crossentropy'
)
adversarial_algorithm.fit(
    x_real_samples,
    to_categorical(y_real_samples, num_classes=number_samples_per_class["number_classes"]),
    epochs=1000,
    batch_size=32
)
samples = adversarial_algorithm.get_samples(number_samples_per_class)</code></pre>
                    </div>

                    <h4>CGAN Parameters</h4>
                    <table class="parameter-table">
                        <thead>
                            <tr>
                                <th>Parameter</th>
                                <th>Description</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr><td>--adversarial_number_epochs</td><td>Number of training epochs</td></tr>
                            <tr><td>--adversarial_batch_size</td><td>Training batch size</td></tr>
                            <tr><td>--adversarial_initializer_mean</td><td>Mean for weight initialization</td></tr>
                            <tr><td>--adversarial_initializer_deviation</td><td>Std dev for weight initialization</td></tr>
                            <tr><td>--adversarial_latent_dimension</td><td>Latent space dimension</td></tr>
                            <tr><td>--adversarial_training_algorithm</td><td>Training algorithm</td></tr>
                            <tr><td>--adversarial_activation_function</td><td>Activation function</td></tr>
                            <tr><td>--adversarial_dropout_decay_rate_g</td><td>Generator dropout rate</td></tr>
                            <tr><td>--adversarial_dropout_decay_rate_d</td><td>Discriminator dropout rate</td></tr>
                            <tr><td>--adversarial_dense_layer_sizes_g</td><td>Generator layer sizes</td></tr>
                            <tr><td>--adversarial_dense_layer_sizes_d</td><td>Discriminator layer sizes</td></tr>
                            <tr><td>--adversarial_latent_mean_distribution</td><td>Latent space mean</td></tr>
                            <tr><td>--adversarial_latent_stander_deviation</td><td>Latent space std dev</td></tr>
                            <tr><td>--adversarial_loss_generator</td><td>Generator loss function</td></tr>
                            <tr><td>--adversarial_loss_discriminator</td><td>Discriminator loss function</td></tr>
                            <tr><td>--adversarial_smoothing_rate</td><td>Label smoothing rate</td></tr>
                        </tbody>
                    </table>
                </div>

                <div class="workflow-section">
                    <h3>Wasserstein GAN-GP</h3>
                    <div class="code-block">
                        <pre><code>import numpy
import tensorflow
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from SynDataGen.Engine.Models.Wasserstein.ModelWassersteinGAN import WassersteinModel
from SynDataGen.Engine.Algorithms.Wasserstein.AlgorithmWassersteinGan import WassersteinAlgorithm

number_samples_per_class = {
    "classes": {1: 100, 2: 200, 3: 150},
    "number_classes": 3
}
input_shape = (1200, )

# Initialize Wasserstein Model
wasserstein_model = WassersteinModel(
    latent_dimension=128,
    output_shape=input_shape,
    activation_function="LeakyReLU",
    initializer_mean=0.0,
    initializer_deviation=0.02,
    dropout_decay_rate_g=0.2,
    dropout_decay_rate_d=0.4,
    last_layer_activation="sigmoid",
    dense_layer_sizes_g=[128],
    dense_layer_sizes_d=[128],
    dataset_type=numpy.float32,
    number_samples_per_class=number_samples_per_class
)

# Initialize Wasserstein Algorithm
wasserstein_algorithm = WassersteinAlgorithm(
    generator_model=wasserstein_model.get_generator(),
    discriminator_model=wasserstein_model.get_discriminator(),
    latent_dimension=128,
    generator_loss_fn="binary_crossentropy",
    discriminator_loss_fn="binary_crossentropy",
    file_name_discriminator="discriminator_model",
    file_name_generator="generator_model",
    models_saved_path="models_saved/",
    latent_mean_distribution=0.0,
    latent_stander_deviation=1.0,
    smoothing_rate=0.15,
    gradient_penalty_weight=10.0,
    discriminator_steps=3
)

# Train and generate samples
wasserstein_algorithm.compile(
    Adam(learning_rate=0.0002, beta_1=0.5),
    Adam(learning_rate=0.0002, beta_1=0.5),
    generator_loss,
    discriminator_loss
)
wasserstein_algorithm.fit(
    x_real_samples,
    to_categorical(y_real_samples, num_classes=number_samples_per_class["number_classes"]),
    epochs=1000,
    batch_size=32
)
samples = wasserstein_algorithm.get_samples(number_samples_per_class)</code></pre>
                    </div>

                    <h4>WGAN-GP Parameters</h4>
                    <table class="parameter-table">
                        <thead>
                            <tr>
                                <th>Parameter</th>
                                <th>Description</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr><td>--wasserstein_latent_dimension</td><td>Latent space dimension</td></tr>
                            <tr><td>--wasserstein_training_algorithm</td><td>Training algorithm</td></tr>
                            <tr><td>--wasserstein_activation_function</td><td>Activation function</td></tr>
                            <tr><td>--wasserstein_dropout_decay_rate_g</td><td>Generator dropout rate</td></tr>
                            <tr><td>--wasserstein_dropout_decay_rate_d</td><td>Discriminator dropout rate</td></tr>
                            <tr><td>--wasserstein_dense_layer_sizes_generator</td><td>Generator layer sizes</td></tr>
                            <tr><td>--wasserstein_dense_layer_sizes_discriminator</td><td>Discriminator layer sizes</td></tr>
                            <tr><td>--wasserstein_batch_size</td><td>Training batch size</td></tr>
                            <tr><td>--wasserstein_number_epochs</td><td>Number of training epochs</td></tr>
                            <tr><td>--wasserstein_number_classes</td><td>Number of classes</td></tr>
                            <tr><td>--wasserstein_loss_function</td><td>Loss function</td></tr>
                            <tr><td>--wasserstein_momentum</td><td>Optimizer momentum</td></tr>
                            <tr><td>--wasserstein_last_activation_layer</td><td>Last layer activation</td></tr>
                            <tr><td>--wasserstein_initializer_mean</td><td>Weight initialization mean</td></tr>
                            <tr><td>--wasserstein_initializer_deviation</td><td>Weight initialization std dev</td></tr>
                            <tr><td>--wasserstein_gradient_penalty</td><td>Gradient penalty weight</td></tr>
                        </tbody>
                    </table>
                </div>

                <div class="workflow-section">
                    <h3>Conditional Autoencoder (CAE)</h3>
                    <div class="code-block">
                        <pre><code>import numpy
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from SynDataGen.Engine.Models.Autoencoder.ModelAutoencoder import AutoencoderModel
from SynDataGen.Engine.Algorithms.Autoencoder.AutoencoderAlgorithm import AutoencoderAlgorithm

number_samples_per_class = {
    "classes": {1: 100, 2: 200, 3: 150},
    "number_classes": 3
}
input_shape = (1200, )

# Initialize Autoencoder Model
autoencoder_model = AutoencoderModel(
    latent_dimension=64,
    output_shape=input_shape,
    activation_function="LeakyReLU",
    initializer_mean=0.0,
    initializer_deviation=0.50,
    dropout_decay_encoder=0.2,
    dropout_decay_decoder=0.2,
    last_layer_activation="sigmoid",
    number_neurons_encoder=[256, 128],
    number_neurons_decoder=[128, 256],
    dataset_type=numpy.float32,
    number_samples_per_class=2
)

# Initialize Autoencoder Algorithm
autoencoder_algorithm = AutoencoderAlgorithm(
    encoder_model=autoencoder_model.get_encoder(input_shape),
    decoder_model=autoencoder_model.get_decoder(input_shape),
    loss_function="binary_crossentropy",
    file_name_encoder="encoder_model",
    file_name_decoder="decoder_model",
    models_saved_path="models_saved/",
    latent_mean_distribution=0.5,
    latent_stander_deviation=0.5,
    latent_dimension=64
)

# Train and generate samples
autoencoder_algorithm.compile(loss='mse')
autoencoder_algorithm.fit(
    (x_real_samples, to_categorical(y_real_samples, num_classes=number_samples_per_class["number_classes"])),
    x_real_samples,
    epochs=1000,
    batch_size=32
)
samples = autoencoder_algorithm.get_samples(number_samples_per_class)</code></pre>
                    </div>

                    <h4>CAE Parameters</h4>
                    <table class="parameter-table">
                        <thead>
                            <tr>
                                <th>Parameter</th>
                                <th>Description</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr><td>--autoencoder_latent_dimension</td><td>Latent space dimension</td></tr>
                            <tr><td>--autoencoder_training_algorithm</td><td>Training algorithm</td></tr>
                            <tr><td>--autoencoder_activation_function</td><td>Activation function</td></tr>
                            <tr><td>--autoencoder_dropout_decay_rate_encoder</td><td>Encoder dropout rate</td></tr>
                            <tr><td>--autoencoder_dropout_decay_rate_decoder</td><td>Decoder dropout rate</td></tr>
                            <tr><td>--autoencoder_dense_layer_sizes_encoder</td><td>Encoder layer sizes</td></tr>
                            <tr><td>--autoencoder_dense_layer_sizes_decoder</td><td>Decoder layer sizes</td></tr>
                            <tr><td>--autoencoder_batch_size</td><td>Training batch size</td></tr>
                            <tr><td>--autoencoder_number_classes</td><td>Number of classes</td></tr>
                            <tr><td>--autoencoder_number_epochs</td><td>Number of training epochs</td></tr>
                            <tr><td>--autoencoder_loss_function</td><td>Loss function</td></tr>
                            <tr><td>--autoencoder_momentum</td><td>Optimizer momentum</td></tr>
                            <tr><td>--autoencoder_last_activation_layer</td><td>Last layer activation</td></tr>
                            <tr><td>--autoencoder_initializer_mean</td><td>Weight initialization mean</td></tr>
                            <tr><td>--autoencoder_initializer_deviation</td><td>Weight initialization std dev</td></tr>
                        </tbody>
                    </table>
                </div>

                <div class="workflow-section">
                    <h3>Variational Autoencoder (VAE)</h3>
                    <div class="code-block">
                        <pre><code>import numpy
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from SynDataGen.Engine.Models.VariationalAutoencoder.VariationalAutoencoderModel import VariationalModel
from SynDataGen.Engine.Algorithms.VariationalAutoencoder.AlgorithmVariationalAutoencoder import VariationalAlgorithm

number_samples_per_class = {
    "classes": {1: 100, 2: 200, 3: 150},
    "number_classes": 3
}
input_shape = (1200, )

# Initialize Variational Model
variation_model = VariationalModel(
    latent_dimension=128,
    output_shape=input_shape,
    activation_function="LeakyReLU",
    initializer_mean=0.0,
    initializer_deviation=0.02,
    dropout_decay_encoder=0.2,
    dropout_decay_decoder=0.4,
    last_layer_activation="sigmoid",
    number_neurons_encoder=[128],
    number_neurons_decoder=[128],
    dataset_type=numpy.float32,
    number_samples_per_class=2
)

# Initialize Variational Algorithm
variational_algorithm = VariationalAlgorithm(
    encoder_model=variation_model.get_encoder(),
    decoder_model=variation_model.get_decoder(),
    loss_function="binary_crossentropy",
    latent_dimension=64,
    decoder_latent_dimension=128,
    latent_mean_distribution=0.0,
    latent_stander_deviation=0.5,
    file_name_encoder="encoder_model",
    file_name_decoder="decoder_model",
    models_saved_path="models_saved/"
)

# Train and generate samples
variational_algorithm.compile()
variational_algorithm.fit(
    (x_real_samples, to_categorical(y_real_samples, num_classes=number_samples_per_class["number_classes"])),
    epochs=1000,
    batch_size=32
)
samples = variational_algorithm.get_samples(number_samples_per_class)</code></pre>
                    </div>

                    <h4>VAE Parameters</h4>
                    <table class="parameter-table">
                        <thead>
                            <tr>
                                <th>Parameter</th>
                                <th>Description</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr><td>--variational_autoencoder_latent_dimension</td><td>Latent space dimension</td></tr>
                            <tr><td>--variational_autoencoder_training_algorithm</td><td>Training algorithm</td></tr>
                            <tr><td>--variational_autoencoder_activation_function</td><td>Activation function</td></tr>
                            <tr><td>--variational_autoencoder_dropout_decay_rate_encoder</td><td>Encoder dropout rate</td></tr>
                            <tr><td>--variational_autoencoder_dropout_decay_rate_decoder</td><td>Decoder dropout rate</td></tr>
                            <tr><td>--variational_autoencoder_dense_layer_sizes_encoder</td><td>Encoder layer sizes</td></tr>
                            <tr><td>--variational_autoencoder_dense_layer_sizes_decoder</td><td>Decoder layer sizes</td></tr>
                            <tr><td>--variational_autoencoder_number_epochs</td><td>Number of training epochs</td></tr>
                            <tr><td>--variational_autoencoder_batch_size</td><td>Training batch size</td></tr>
                            <tr><td>--variational_autoencoder_number_classes</td><td>Number of classes</td></tr>
                            <tr><td>--variational_autoencoder_loss_function</td><td>Loss function</td></tr>
                            <tr><td>--variational_autoencoder_momentum</td><td>Optimizer momentum</td></tr>
                            <tr><td>--variational_autoencoder_last_activation_layer</td><td>Last layer activation</td></tr>
                            <tr><td>--variational_autoencoder_initializer_mean</td><td>Weight initialization mean</td></tr>
                            <tr><td>--variational_autoencoder_initializer_deviation</td><td>Weight initialization std dev</td></tr>
                            <tr><td>--variational_autoencoder_mean_distribution</td><td>Latent space mean</td></tr>
                            <tr><td>--variational_autoencoder_stander_deviation</td><td>Latent space std dev</td></tr>
                        </tbody>
                    </table>
                </div>
            </div>

            <div class="features-section">
                <h2 id="common-parameters">Common Parameters</h2>

                <h3>Data Loading Parameters</h3>
                <table class="parameter-table">
                    <thead>
                        <tr>
                            <th>Parameter</th>
                            <th>Description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td>-i, --data_load_path_file_input</td><td>Path to input CSV file</td></tr>
                        <tr><td>--data_load_label_column</td><td>Index of label column</td></tr>
                        <tr><td>--data_load_max_samples</td><td>Maximum samples to load</td></tr>
                        <tr><td>--data_load_max_columns</td><td>Maximum columns to consider</td></tr>
                        <tr><td>--data_load_start_column</td><td>First column index</td></tr>
                        <tr><td>--data_load_end_column</td><td>Last column index</td></tr>
                        <tr><td>--data_load_path_file_output</td><td>Output CSV path</td></tr>
                        <tr><td>--data_load_exclude_columns</td><td>Columns to exclude</td></tr>
                    </tbody>
                </table>

                <h3>Classifier Parameters</h3>

                <h4>Support Vector Machine</h4>
                <table class="parameter-table">
                    <thead>
                        <tr>
                            <th>Parameter</th>
                            <th>Description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td>--support_vector_machine_regularization</td><td>Regularization parameter</td></tr>
                        <tr><td>--support_vector_machine_kernel</td><td>Kernel type</td></tr>
                        <tr><td>--support_vector_machine_kernel_degree</td><td>Polynomial kernel degree</td></tr>
                        <tr><td>--support_vector_machine_gamma</td><td>Kernel coefficient</td></tr>
                    </tbody>
                </table>

                <h4>Stochastic Gradient Descent</h4>
                <table class="parameter-table">
                    <thead>
                        <tr>
                            <th>Parameter</th>
                            <th>Description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td>--stochastic_gradient_descent_loss</td><td>Loss function</td></tr>
                        <tr><td>--stochastic_gradient_descent_penalty</td><td>Regularization penalty</td></tr>
                        <tr><td>--stochastic_gradient_descent_alpha</td><td>Regularization term</td></tr>
                        <tr><td>--stochastic_gradient_descent_max_iterations</td><td>Maximum iterations</td></tr>
                        <tr><td>--stochastic_gradient_descent_tolerance</td><td>Stopping criteria tolerance</td></tr>
                    </tbody>
                </table>

                <h4>Random Forest</h4>
                <table class="parameter-table">
                    <thead>
                        <tr>
                            <th>Parameter</th>
                            <th>Description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td>--random_forest_number_estimators</td><td>Number of trees</td></tr>
                        <tr><td>--random_forest_max_depth</td><td>Maximum tree depth</td></tr>
                        <tr><td>--random_forest_max_leaf_nodes</td><td>Maximum leaf nodes</td></tr>
                    </tbody>
                </table>

                <h4>Quadratic Discriminant Analysis</h4>
                <table class="parameter-table">
                    <thead>
                        <tr>
                            <th>Parameter</th>
                            <th>Description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td>--quadratic_discriminant_analysis_priors</td><td>Class probabilities</td></tr>
                        <tr><td>--quadratic_discriminant_analysis_regularization</td><td>Regularization parameter</td></tr>
                        <tr><td>--quadratic_discriminant_analysis_threshold</td><td>Threshold value</td></tr>
                    </tbody>
                </table>

                <h4>Multilayer Perceptron</h4>
                <table class="parameter-table">
                    <thead>
                        <tr>
                            <th>Parameter</th>
                            <th>Description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td>--perceptron_training_algorithm</td><td>Training algorithm</td></tr>
                        <tr><td>--perceptron_training_loss</td><td>Loss function</td></tr>
                        <tr><td>--perceptron_layers_settings</td><td>Layer configurations</td></tr>
                        <tr><td>--perceptron_dropout_decay_rate</td><td>Dropout rate</td></tr>
                        <tr><td>--perceptron_training_metric</td><td>Evaluation metrics</td></tr>
                        <tr><td>--perceptron_layer_activation</td><td>Layer activation</td></tr>
                        <tr><td>--perceptron_last_layer_activation</td><td>Output activation</td></tr>
                        <tr><td>--perceptron_number_epochs</td><td>Training epochs</td></tr>
                    </tbody>
                </table>

                <h4>Spectral Clustering</h4>
                <table class="parameter-table">
                    <thead>
                        <tr>
                            <th>Parameter</th>
                            <th>Description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td>--spectral_number_clusters</td><td>Number of clusters</td></tr>
                        <tr><td>--spectral_eigen_solver</td><td>Eigenvalue decomposition method</td></tr>
                        <tr><td>--spectral_affinity</td><td>Affinity matrix construction</td></tr>
                        <tr><td>--spectral_assign_labels</td><td>Label assignment strategy</td></tr>
                        <tr><td>--spectral_random_state</td><td>Random seed</td></tr>
                    </tbody>
                </table>

                <h4>Linear Regression</h4>
                <table class="parameter-table">
                    <thead>
                        <tr>
                            <th>Parameter</th>
                            <th>Description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td>--linear_regression_fit_intercept</td><td>Whether to calculate intercept</td></tr>
                        <tr><td>--linear_regression_normalize</td><td>Normalize features</td></tr>
                        <tr><td>--linear_regression_copy_X</td><td>Copy input data</td></tr>
                        <tr><td>--linear_regression_number_jobs</td><td>Number of parallel jobs</td></tr>
                    </tbody>
                </table>

                <h4>Naive Bayes</h4>
                <table class="parameter-table">
                    <thead>
                        <tr>
                            <th>Parameter</th>
                            <th>Description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td>--naive_bayes_priors</td><td>Class probabilities</td></tr>
                        <tr><td>--naive_bayes_variation_smoothing</td><td>Smoothing parameter</td></tr>
                    </tbody>
                </table>

                <h4>K-Nearest Neighbors</h4>
                <table class="parameter-table">
                    <thead>
                        <tr>
                            <th>Parameter</th>
                            <th>Description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td>--knn_number_neighbors</td><td>Number of neighbors</td></tr>
                        <tr><td>--knn_weights</td><td>Weight function</td></tr>
                        <tr><td>--knn_algorithm</td><td>Algorithm used</td></tr>
                        <tr><td>--knn_leaf_size</td><td>Leaf size for tree algorithms</td></tr>
                        <tr><td>--knn_metric</td><td>Distance metric</td></tr>
                    </tbody>
                </table>

                <h4>K-Means</h4>
                <table class="parameter-table">
                    <thead>
                        <tr>
                            <th>Parameter</th>
                            <th>Description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td>--k_means_number_clusters</td><td>Number of clusters</td></tr>
                        <tr><td>--k_means_init</td><td>Initialization method</td></tr>
                        <tr><td>--k_means_max_iterations</td><td>Maximum iterations</td></tr>
                        <tr><td>--k_means_tolerance</td><td>Convergence tolerance</td></tr>
                        <tr><td>--k_means_random_state</td><td>Random seed</td></tr>
                    </tbody>
                </table>


                <h4>Gradient Boosting</h4>
                <table class="parameter-table">
                    <thead>
                        <tr>
                            <th>Parameter</th>
                            <th>Description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td>--gradient_boosting_loss</td><td>Loss function</td></tr>
                        <tr><td>--gradient_boosting_learning_rate</td><td>Learning rate</td></tr>
                        <tr><td>--gradient_boosting_number_estimators</td><td>Number of estimators</td></tr>
                        <tr><td>--gradient_boosting_subsample</td><td>Subsample ratio</td></tr>
                        <tr><td>--gradient_boosting_criterion</td><td>Split quality measure</td></tr>
                    </tbody>
                </table>

                <h4>Gaussian Process</h4>
                <table class="parameter-table">
                    <thead>
                        <tr>
                            <th>Parameter</th>
                            <th>Description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td>--gaussian_process_kernel</td><td>Kernel function</td></tr>
                        <tr><td>--gaussian_process_max_iterations</td><td>Maximum iterations</td></tr>
                        <tr><td>--gaussian_process_optimizer</td><td>Optimizer method</td></tr>
                    </tbody>
                </table>

                <h4>Decision Tree</h4>
                <table class="parameter-table">
                    <thead>
                        <tr>
                            <th>Parameter</th>
                            <th>Description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td>--decision_tree_criterion</td><td>Split quality measure</td></tr>
                        <tr><td>--decision_tree_max_depth</td><td>Maximum tree depth</td></tr>
                        <tr><td>--decision_tree_max_features</td><td>Features to consider</td></tr>
                        <tr><td>--decision_tree_max_leaf_nodes</td><td>Maximum leaf nodes</td></tr>
                    </tbody>
                </table>
            </div>
        </div>
    </section>
</main>

</body>
</html>
